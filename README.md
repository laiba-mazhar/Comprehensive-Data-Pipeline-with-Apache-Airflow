# Comprehensive-Data-Pipeline-with-Apache-Airflow

## Project Overview
This project aims to analyze the Brazilian E-Commerce Public Dataset by Olist using Apache Airflow. The workflow involves extracting, preprocessing, and analyzing data to generate insightful visualizations.

## Project Structure
- **Dag Directory**: Contains the main DAG script `olist_analysis_dag.py` which orchestrates the data pipeline.
- **Data Directory**: Contains nine CSV files that serve as the data sources for the analysis.
- **Screenshots**: Three screenshots of the output visualizations generated by the workflow.

## Workflow
The data pipeline is defined in `olist_analysis_dag.py` and includes the following steps:

1. **Data Extraction**:
   - Reads the CSV files into Pandas DataFrames.
   - Saves the DataFrames as temporary files for downstream tasks.

2. **Data Preprocessing**:
   - Handles missing values and converts date columns to appropriate formats.
   - Saves the processed data for analysis.

3. **Data Analysis**:
   - Performs a sample analysis to calculate the monthly order count.
   - Generates and saves a bar plot of the monthly order count.

## Prerequisites
- Apache Airflow installed and configured.
- Required Python libraries: Pandas, Matplotlib.

## How to Run the Project
1. Place the CSV files in the `data` directory.
2. Ensure Apache Airflow is running.
3. Trigger the DAG `olist_analysis_dag` from the Airflow web interface.


## Screenshots
![ss1](https://github.com/user-attachments/assets/df0f7a5a-ed41-4ee1-9788-8ad1e805431f)
![ss2](https://github.com/user-attachments/assets/ce791365-05df-4ac8-86eb-d5ac1757a9a9)
![ss3](https://github.com/user-attachments/assets/77ed9f14-3b8d-46d6-84c8-3c2cbb57fa9c)

## Author
- Laiba Mazhar
  
## Contact
For more information contact:
[laibamazhar.000@gmail.com]
